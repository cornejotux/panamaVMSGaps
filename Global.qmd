---
title: "Documention"
author: "Jorge Cornejo"
format: html
editor: visual
---

## Access the data

```{r libraries, message=FALSE, warning=FALSE, echo=F, results=F}
rm(list=ls())
require(dplyr)
require(lubridate)
require(sf)
#library(here)
library(ggplot2)
#install.packages("devtools")
#devtools::install_github("GlobalFishingWatch/fishwatchr")
library(fishwatchr)
require(kableExtra)
library("sftrack")

#Esto permite que los meses se pongan en espa√±ol
Sys.setlocale("LC_TIME", "es_ES.UTF-8")
format <- "%a@%A@%b@%B@%p@"
#enc2utf8(unique(format(lubridate:::.date_template, format = format)))

con <- DBI::dbConnect(drv = bigrquery::bigquery(), 
                      project = "world-fishing-827", 
                      use_legacy_sql = FALSE)
```

# Get VMS data

```{r eval=F}
#{sql vms, connection=con, output.var="montlyGaps"}
#

with 
gaps as (
SELECT * #ssvid, lat, lon, nnet_score, source, timestamp, EXTRACT(ISOYEAR FROM timestamp) AS year
  FROM `world-fishing-827.pipe_panama_production_v20211126.research_positions`
  where EXTRACT(ISOYEAR FROM timestamp) = 2024
    and hours > 5 and speed > 1 
  order by ssvid, timestamp
),
timeGaps as (
  select distinct timestamp, seg_id
  from gaps
  #limit 10
),

segGaps as (
  select rp.*, ST_GEOGPOINT(lon, lat) as point,
    st_makeline(st_geogpoint(lon,lat),st_geogpoint(lag(lon, 1) over(partition by ssvid order by rp.timestamp),
                                                   lag(lat, 1) over(partition by ssvid order by rp.timestamp))) as geom_line,
  from `world-fishing-827.pipe_panama_production_v20211126.research_positions` as rp
  join timeGaps as tp
  on rp.seg_id = tp.seg_id and
     rp.timestamp BETWEEN DATE_ADD(tp.timestamp, INTERVAL -2 day)
                      AND DATE_ADD(tp.timestamp, INTERVAL 2 day)
)

select *
from segGaps
order by ssvid, timestamp

```

```{r}
# montlyGaps <- montlyGaps %>% 
#               select(-nnet_score, -distance_from_port_m, 
#                     -distance_from_shore_m, -elevation_m, 
#                     -source, -point, -geom_line)
#   
#save(montlyGaps, file="VMSGaps/data/montlyGaps.rds")
load(file="VMSGaps/data/montlyGaps.rds")

```

# Get the AIS data for the VMS gaps

## First, get the time range of the gap

```{r}
require(glue)
require(DBI)
require(RSQLite)
timeRange <- montlyGaps %>% 
  filter(hours >= 3)

tt <- glue_sql("{timeRange*}", .con = con)

vesselList <- unique(timeRange$ssvid)
vessels <- glue_sql("{vesselList*}", .con = con)
```

Now I create a table in BQ so then I can use it to select the time window for the 
AIS data.

```{r}
bq_tbl <- bq_table("world-fishing-827", "scratch_JorgeCornejo", "timeGapsVMSPanama")
bq_table_delete(bq_tbl)
bq_table_create(bq_tbl, timeRange)
job <- bq_table_upload(x=bq_tbl,values=timeRange,
                       quiet = FALSE)

```


## Now get AIS for the gaps

```{r eval=F}
#{sql vms, connection=con, output.var="aisxgaps"}
#

with
  gaps as (
    select * 
    from `world-fishing-827.scratch_JorgeCornejo.timeGapsVMSPanama`
  ),

v as (
  select DISTINCT ssvid as name
  from gaps
),

vessel as (
  SELECT #vessel_id, 
         info.ssvid, shipname.value as fullName, n_shipname.value as n_name,
         gaps.timestamp as gtime, gaps.hours as gapHours #, gaps.ssvid as name
    FROM `world-fishing-827.pipe_ais_v3_published.vessel_info` as info
    join gaps
    on n_shipname.value = gaps.ssvid
),

m as (
  SELECT fullName, n_name, mes.ssvid as ssvid, timestamp, lat, lon, gapHours
  FROM `world-fishing-827.pipe_ais_v3_published.messages`  as mes
  join vessel
    on mes.ssvid = vessel.ssvid and
     #on rp.seg_id = tp.seg_id and
     timestamp BETWEEN DATE_ADD(gtime, INTERVAL -1 day)
                      AND DATE_ADD(gtime, INTERVAL 1 day)
    WHERE
       TIMESTAMP_TRUNC(timestamp, DAY) >= TIMESTAMP("2024-01-01") 
       #and mes.ssvid = "372770000"
)

 
select *
from m
```
Now save an read the data, so we don't run the query every time.

```{r}
#save(aisxgaps, file="VMSGaps/data/aisForGaps.rds")
load(file="VMSGaps/data/aisForGaps.rds")
```

